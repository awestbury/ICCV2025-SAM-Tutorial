<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>ICCV 2025 Workshop on Segment Anything</title>
  <style>
    body {
      font-family: sans-serif;
      max-width: 800px;
      margin: auto;
      padding: 40px;
      line-height: 1.6;
    }
    h1, h2 {
      color: #333;
    }
    ul {
      padding-left: 20px;
    }
    footer {
      margin-top: 40px;
      font-size: 0.9em;
      color: #777;
    }
  </style>
</head>
<body>
  <h1>ICCV 2025 Workshop on Segment Anything</h1>
  <p><strong>Date:</strong> October 19-20, 2025<br>
     <strong>Location:</strong> ICCV 2025, Honolulu, Hawaii</p>

  <p><strong>From Segment Anything to Generalized Visual Grounding</strong> In this tutorial, Meta AI and its academic partners will overview frontier research on visual grounding. We will cover each building block necessary to move toward future general purpose visual grounding systems, including universal image and video encoding, multimodal language understanding, semantic instance segmentation and tracking, and the latest in 3D reconstructions methods. We will provide practical guidance on using SAM open source models, resources, and tooling to tackle the fieldâ€™s biggest open research problems.</p>


  <h2>Organizers</h2>
  <ul>
    <li>Kate Saenko, Boston University & Meta AI</li>
    <li>Muhammad Maaz, Mohamed bin Zayed University of Artificial Intelligence & Meta AI</li>
    <li>Andrew Westbury, Meta AI</li>
  </ul>

  <h2>Contact</h2>
  <p>Email us at: <a href="awestbury@meta.com">awestbury@meta.com</a></p>

  <footer>
    <p>Last updated: August 2025</p>
  </footer>
</body>
</html>
